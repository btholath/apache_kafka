Goal: Multiple Brokers in Kafka 4.0.0 (KRaft Mode)
Each Kafka node (broker/controller) will run independently with:
- A unique node.id
- A shared controller.quorum.voters config so they can discover and elect a controller
- Its own data/log directory


ğŸ—ï¸ Architecture Example (3-Node Cluster)

Node ID	    Role	            Hostname / IP	        Ports
1	        Controller + Broker	node1:9092	            Controller: 9093
2	        Broker	            node2:9092	            Controller: 9093
3	        Broker	            node3:9092	            Controller: 9093

ğŸ”§ Step-by-Step Setup for Each Node
ğŸŸ© 1. Assign a Unique node.id
Each Kafka instance must have its own unique node ID:

node.id=1  # (Change this for each node: 1, 2, 3, ...)

ğŸŸ© 2. Define Common Controller Quorum
All nodes must agree on the controller quorum (static):
controller.quorum.voters=1@node1:9093,2@node2:9093,3@node3:9093
This tells each node which other nodes participate in leader election and metadata storage.

ğŸŸ© 3. Define Roles
Usually, all nodes can have both roles for simplicity:

process.roles=broker,controller
You can also separate roles if needed (e.g., dedicated controller-only nodes).

ğŸŸ© 4. Set Listeners
Set listeners and advertised.listeners per node:

listeners=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
advertised.listeners=PLAINTEXT://node1:9092  # Use actual IP or hostname
controller.listener.names=CONTROLLER
inter.broker.listener.name=PLAINTEXT

ğŸŸ© 5. Use a Unique Log Directory
Each node must have its own storage directory:
log.dirs=/tmp/kafka-logs-node1

ğŸŸ© 6. Format the Storage (Only Once Per Node)
Use a shared cluster-id for all nodes:
export CLUSTER_ID=$(bin/kafka-storage.sh random-uuid)
Then format each node with its unique node.id and shared config:

bin/kafka-storage.sh format -t $CLUSTER_ID -c config/kraft/server.properties

âœ… 7. Start Each Broker

bin/kafka-server-start.sh config/kraft/server.properties
Do this for all nodes â€” once they come online, they'll elect a controller and replicate metadata via the Raft protocol.

ğŸ§  Summary of Key Differences from ZooKeeper
Feature	        ZooKeeper Mode	        KRaft Mode (Kafka 4.0+)
Metadata store	ZooKeeper	            Built-in Raft log
Unique ID	    broker.id	            node.id
Coordination	ZooKeeper	            controller.quorum.voters
Startup format	Not needed	            kafka-storage.sh format





Here's a complete setup plan for deploying a 3-node Kafka 4.0.0 KRaft cluster across DigitalOcean droplets.

ğŸ—‚ï¸ Folder Structure per Node (on each droplet)
/opt/kafka-nodeX/
â”œâ”€â”€ bin/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ kraft/
â”‚       â””â”€â”€ server.properties
â”œâ”€â”€ logs/
â””â”€â”€ data/

ğŸ“„ Example: server.properties for Each Node
ğŸ”¹ Common Settings (All nodes)
Replace nodeX and IPs per node.

process.roles=broker,controller
node.id=X  # <- change per node (1, 2, 3)
controller.listener.names=CONTROLLER
inter.broker.listener.name=PLAINTEXT

# Listener settings
listeners=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
advertised.listeners=PLAINTEXT://<NODE_X_PUBLIC_IP>:9092
log.dirs=/opt/kafka-nodeX/data

# Quorum config â€” SAME on all nodes
controller.quorum.voters=1@NODE1_PUBLIC_IP:9093,2@NODE2_PUBLIC_IP:9093,3@NODE3_PUBLIC_IP:9093

ğŸ› ï¸ Set Up Per Node (DigitalOcean Droplet)
Download Kafka 4.0.0

cd /opt
wget https://downloads.apache.org/kafka/4.0.0/kafka_2.13-4.0.0.tgz
tar -xvzf kafka_2.13-4.0.0.tgz
mv kafka_2.13-4.0.0 kafka-nodeX

Create directories:
mkdir -p /opt/kafka-nodeX/data /opt/kafka-nodeX/logs

Edit the KRaft config:
nano /opt/kafka-nodeX/config/kraft/server.properties
Set node.id=X and update IPs.

ğŸ“¦ One-Time Setup: Generate and Share Cluster ID
Do this on one node only:
cd /opt/kafka-node1
export CLUSTER_ID=$(bin/kafka-storage.sh random-uuid)
echo $CLUSTER_ID

Copy the $CLUSTER_ID value, and format storage on each node using:
bin/kafka-storage.sh format -t $CLUSTER_ID -c config/kraft/server.properties

ğŸš€ Start Kafka (on each node)
bin/kafka-server-start.sh config/kraft/server.properties

ğŸ” Startup Script Example (Per Node)
Create /opt/kafka-nodeX/start.sh:
#!/bin/bash
cd /opt/kafka-nodeX
nohup bin/kafka-server-start.sh config/kraft/server.properties > logs/kafka.log 2>&1 &

Make it executable:
chmod +x /opt/kafka-nodeX/start.sh

ğŸ“¡ Open Ports on Each Droplet
sudo ufw allow 9092/tcp
sudo ufw allow 9093/tcp
Or configure DigitalOcean firewall to allow 9092 & 9093 between the 3 nodes and your client machine.

ğŸ§ª Validate Cluster
Run this on any node:
bin/kafka-topics.sh --bootstrap-server <node-ip>:9092 --list

You should be able to create topics, produce, and consume as normal.
